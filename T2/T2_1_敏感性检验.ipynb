{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 4\n",
    "data1 = pd.read_csv(\"../data_after_cleaning.csv\")\n",
    "\n",
    "X_without_noise = data1.drop(columns=['type'])\n",
    "y_without_noise = data1['type']\n",
    "\n",
    "X_train_without_noise, X_test_without_noise, y_train_without_noise, y_test_without_noise = train_test_split(X_without_noise, y_without_noise, test_size=0.4, random_state=SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K2O 0.137\n",
      "Na2O 0.088\n",
      "CaO 0.085\n",
      "Al2O3 0.039\n",
      "CuO 0.032\n",
      "P2O5 -0.005\n",
      "SiO 0.002\n",
      "Fe2O3 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "from SALib.test_functions import Ishigami\n",
    "import math\n",
    "\n",
    "# lasso 回归 模型\n",
    "\n",
    "# 模型参数\n",
    "ALPHA = 0.0125\n",
    "\n",
    "# 学习模型\n",
    "lasso = Lasso(alpha=ALPHA)\n",
    "lasso.fit(X_train_without_noise, y_train_without_noise)\n",
    "\n",
    "def classification_func(X):\n",
    "    return lasso.predict(X)>=1/2\n",
    "\n",
    "parms = {\n",
    "    'num_vars' : 8,\n",
    "    'names' : ['SiO', 'Na2O', 'K2O', 'CaO', 'Al2O3', 'Fe2O3', 'CuO', 'P2O5'],\n",
    "    'bounds' : [[0,100]] * 8\n",
    "}\n",
    "\n",
    "param_values = saltelli.sample(parms, 2**10)\n",
    "Y = np.zeros([param_values.shape[0]])\n",
    "\n",
    "for i, X in enumerate(param_values):\n",
    "    Y[i] = classification_func(np.array([X,]))\n",
    "\n",
    "\n",
    "Si = sobol.analyze(parms, Y)\n",
    "\n",
    "result = []\n",
    "\n",
    "for i in range(8):\n",
    "    result.append((parms['names'][i], Si['S1'][i]))\n",
    "\n",
    "result.sort(key=lambda x: -abs(x[1]))\n",
    "result\n",
    "for key, value in result:\n",
    "    print(f'{key} {value:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 制作含有扰动的数据集\n",
    "\n",
    "SEED = 4\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 噪声设置为 0.1 , x -> (x +- (0~0.1)*x)\n",
    "NOISE = 0.1\n",
    "\n",
    "data = pd.read_csv(\"../data_after_cleaning.csv\")\n",
    "data1 = data['type']\n",
    "data2 = data.drop(columns=['type'])\n",
    "data2 = data2.apply(lambda x: x * (1 + (np.random.randn() * 2 - 1) * NOISE))\n",
    "\n",
    "pd.concat([data1, data2], axis=1).to_csv(\"../data_after_cleaning_with_noise.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data1 = pd.read_csv(\"../data_after_cleaning.csv\")\n",
    "data2 = pd.read_csv(\"../data_after_cleaning_with_noise.csv\")\n",
    "\n",
    "X_without_noise = data1.drop(columns=['type'])\n",
    "y_without_noise = data1['type']\n",
    "X_with_noise = data2.drop(columns=['type'])\n",
    "y_with_noise = data2['type']\n",
    "\n",
    "X_train_without_noise, X_test_without_noise, y_train_without_noise, y_test_without_noise = train_test_split(X_without_noise, y_without_noise, test_size=0.4, random_state=SEED)\n",
    "X_train_with_noise, X_test_with_noise, y_train_with_noise, y_test_with_noise = train_test_split(X_with_noise, y_with_noise, test_size=0.4, random_state=SEED)\n",
    "\n",
    "def noise_test(pred_func, classification_func, model_name):\n",
    "    cr1 = classification_report(y_test_without_noise, classification_func(X_test_without_noise), output_dict=True)\n",
    "    cr2 = classification_report(y_test_with_noise, classification_func(X_test_with_noise), output_dict=True)\n",
    "    # none_noise model_name; class0(未风化): precision recall f1-score; class1(已风化) precision recall f1-score\n",
    "    print(f\"{model_name}\\t{cr1['0']['precision']:.2f}\\t{cr1['0']['recall']:.2f}\\t{cr1['0']['f1-score']:.2f}\\t{cr1['1']['precision']:.2f}\\t{cr1['1']['recall']:.2f}\\t{cr1['1']['f1-score']:.2f}\\t\")\n",
    "    print(f\"{model_name}\\t{cr2['0']['precision']:.2f}\\t{cr2['0']['recall']:.2f}\\t{cr2['0']['f1-score']:.2f}\\t{cr2['1']['precision']:.2f}\\t{cr2['1']['recall']:.2f}\\t{cr2['1']['f1-score']:.2f}\\t\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBOOST 决策树模型\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "xgb=XGBClassifier(max_depth=2)\n",
    "xgb.fit(X_train_without_noise,y_train_without_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "std = StandardScaler()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "data_train = X_train_without_noise\n",
    "color = y_train_without_noise\n",
    "data_after_pca = pca.fit_transform(data_train)\n",
    "data_after_pca = pd.DataFrame(data_after_pca)\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(data_after_pca, color)\n",
    "\n",
    "def pca_predict(X):\n",
    "    X = pca.transform(X)\n",
    "    return knn.predict(pd.DataFrame(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t\n",
      "Lasso Regression\t0.95\t1.00\t0.97\t1.00\t0.90\t0.95\t\n",
      "XGBoost\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t\n",
      "XGBoost\t1.00\t1.00\t1.00\t1.00\t1.00\t1.00\t\n",
      "PCA+KNN\t1.00\t0.94\t0.97\t0.91\t1.00\t0.95\t\n",
      "PCA+KNN\t0.90\t1.00\t0.95\t1.00\t0.80\t0.89\t\n"
     ]
    }
   ],
   "source": [
    "noise_test(lasso.predict, classification_func, 'Lasso Regression')\n",
    "noise_test(xgb.predict, xgb.predict, 'XGBoost')\n",
    "noise_test(pca_predict, pca_predict, 'PCA+KNN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "# pca = PCA(n_components=5)\n",
    "# data_train = data.drop([\"type\"], axis=1)\n",
    "# color = data[\"type\"]\n",
    "# data_after_pca = pca.fit_transform(data_train)\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# data_after_pca = pd.DataFrame(data_after_pca)\n",
    "# print(data_after_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "648d8d9586a5c78aacf5d2001e33b7f17efe48eb523fe8964abf0a6c8058fa92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
